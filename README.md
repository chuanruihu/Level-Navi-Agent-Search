# Level-Navi Agent

This repository is the official repository for the paper Level-Navi Agent: A Benchmark and Framework for Chinese Web Search Agents.

## ğŸŒ Project Introduction

Level-Navi Agent is an open-source, general-purpose web search agent framework where any open or closed-source model can be deployed. Our agent is capable of breaking down and understanding complex questions, iteratively searching for information on the internet step by step, until it can answer the user's original question.

<div style="text-align: center;">
    <figure style="display: inline-block; text-align: center;">
        <img src="asset/first.png" width="50%">
        <figcaption>*Framework of Level-Navi Agent</figcaption>
    </figure>
</div>

To comprehensively evaluate the performance of various models on web search tasks, we provide an open-source dataset - Web24 Dataset. The total number of samples in our dataset is 481, and all questions come from five major domains: finance, gaming, sports, movies, and events. Our classification comes from scenarios that people usually search for on the internet. To avoid interference from the model's internal knowledge to the framework, the main source of our dataset is news (before December 2024), and we ensure that there are credible information source links. Questions are divided into simple, conditional, comparative, and multi-hop, covering a variety of questioning scenarios.

<div style="text-align: center;">
    <figure style="display: inline-block; text-align: center;">
        <img src="asset/data.png" width="40%">
        <figcaption>*Web24 Dataset Composition</figcaption>
    </figure>
</div>

Here we provide some model test results, and more comprehensive experiments and analysis can be obtained in the paper.


| Model               | Few-shot    | $S_{final}$ | $S_{co}$ | $S_{rele}$ | $S_{simi}$ | $S_c$ | Pass rate |
|---------------------|-------------|-------------|----------|------------|------------|-------|-----------|
| **Internlm2.5-7B**  | zero-shot   | 49.48       | 0.47     | 0.81       | 0.56       | 2.62  | 0.92      |
|                     | three-shot  | 49.31       | 0.47     | 0.80       | 0.56       | 2.65  | 0.95      |
| **Internlm2.5-20B** | zero-shot   | 55.02       | 0.57     | 0.80       | 0.57       | 3.62  | 0.93      |
|                     | three-shot  | 55.43       | 0.57     | 0.80       | 0.57       | 2.69  | 0.97      |
| **GLM-4-9B**        | zero-shot   | 63.25       | 0.66     | 0.83       | 0.67       | 2.16  | 0.94      |
|                     | three-shot  | 43.43       | 0.37     | 0.81       | 0.56       | 2.69  | 0.92      |
| **Qwen2.5-3B**      | zero-shot   | 60.17       | 0.62     | 0.84       | 0.64       | 2.56  | 0.85      |
|                     | three-shot  | 60.45       | 0.63     | 0.84       | 0.59       | 2.12  | 0.86      |
| **Qwen2.5-7B**      | zero-shot   | 63.12       | 0.65     | 0.85       | 0.60       | 1.44  | 0.99      |
|                     | three-shot  | 65.84       | 0.70     | 0.84       | 0.62       | 1.64  | 1.00      |
| **Qwen2.5-14B**     | zero-shot   | 68.34       | 0.75     | 0.84       | 0.61       | 1.84  | 0.99      |
|                     | three-shot  | 68.39       | 0.75     | 0.84       | 0.61       | 1.81  | 1.00      |
| **Llama3.1-8B**     | zero-shot   | 37.02       | 0.30     | 0.74       | 0.51       | 3.60  | 0.88      |
|                     | three-shot  | 32.45       | 0.27     | 0.61       | 0.46       | 3.89  | 0.93      |

## ğŸ“ Quick Start

æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¿«é€Ÿå¯åŠ¨é¡¹ç›®ï¼š

### 1. Clone the Project

Follow these steps to quickly start the project:

```bash
git clone [project address]
```

### 2. Set Up Environment

Use conda to create a Python 3.11 virtual environment:

```bash
conda create --name ai_search python=3.11
```

### 3. Install Dependencies

Enter the project directory and install dependencies:

```bash
cd [project directory]
pip install -r requirements.txt
```

### 4. Configure Search Engine API

Obtain a [Bing API Key](https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)ï¼Œand configure it in the configuration file(config/.env)(`BING_API`)

### 5. API/Local Mode

#### API Deployment
Obtain an OpenAI API Keyï¼Œchoose a model name, and configure it in the [configuration file](config/.env)(`API_KEY`, `MODEL_NAME`)

#### Local Model Deployment
Use vllm to deploy the local model in server mode.

Configure the model name/path MODEL_NAME_OR_PATH [script file](example/vllm_openai.sh) 

Change  API_BASE='http://localhost:8001/v1' in the [configuration file](config/.env)

Start the vllm service:
```bash
cd example
bash vllm_openai.sh
```

### 6. Start Testing

Activate the virtual environment and run the example code for testing:

```bash
cd example 
python terminal.py
```

### Test Example

```
è¾“å…¥ï¼šåŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ

è¿”å›ç¤ºä¾‹å“åº”ï¼š

åŒ—äº¬2024å¹´12æœˆ12æ—¥çš„å¤©æ°”é¢„æŠ¥å¦‚ä¸‹ï¼š

- **å¤©æ°”çŠ¶å†µ**ï¼šå¤šäº‘è½¬å°é›ª
- **æ¸©åº¦**ï¼š
  - ç™½å¤©æœ€é«˜æ¸©åº¦ï¼š4Â°C
  - å¤œé—´æœ€ä½æ¸©åº¦ï¼š-3Â°C
- **é£å‘é£åŠ›**ï¼š
  - ç™½å¤©ï¼šè¥¿å—é£ï¼Œå¾®é£
  - å¤œé—´ï¼šåŒ—é£ï¼Œå¾®é£
- **ç©ºæ°”è´¨é‡**ï¼šè‰¯å¥½ï¼Œå¯ä»¥æ­£å¸¸å‚åŠ æˆ·å¤–æ´»åŠ¨ï¼ŒAQIä¸º60ï¼Œå±äºâ€œè‰¯â€çº§åˆ«ã€‚

å»ºè®®å‡ºé—¨æ—¶æºå¸¦é›¨å…·ï¼Œå¹¶æ³¨æ„é˜²æ»‘ï¼Œå°¤å…¶æ˜¯åœ¨å¤œé—´å’Œæ—©æ™¨ã€‚å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼
```

```
è¾“å…¥ï¼šOpenAI o1 æœ‰ä»€ä¹ˆå€¼å¾—å…³æ³¨çš„ç‚¹ï¼Ÿ

è¿”å›ç¤ºä¾‹å“åº”ï¼š

### OpenAI o1 çš„ä¸»è¦ç‰¹ç‚¹å’Œå€¼å¾—å…³æ³¨çš„ç‚¹

#### ä¸»è¦ç‰¹ç‚¹

1. **å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰è®­ç»ƒ**ï¼š
   - o1 æ¨¡å‹æ¥å—äº†å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œè¿™æ˜¯å…¶æ ¸å¿ƒç‰¹ç‚¹ä¹‹ä¸€ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡å‹èƒ½å¤Ÿæ ¹æ®åé¦ˆä¸æ–­ä¼˜åŒ–å…¶è¾“å‡ºï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚

2. **æ›´é•¿çš„å†…éƒ¨æ€ç»´é“¾ï¼ˆChain of Thought, CoTï¼‰**ï¼š
   - åœ¨æ¨¡å‹æ¨ç†æ—¶ï¼Œo1 é‡‡ç”¨äº†æ›´é•¿çš„å†…éƒ¨æ€ç»´é“¾ã€‚è¿™æ„å‘³ç€æ¨¡å‹åœ¨å›ç­”é—®é¢˜ä¹‹å‰ä¼šè¿›è¡Œæ›´æ·±å…¥çš„æ€è€ƒï¼Œå°†é—®é¢˜åˆ†è§£æˆæ›´å°çš„æ­¥éª¤é€ä¸€è§£å†³ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®å’Œåˆç†çš„ç­”æ¡ˆã€‚

3. **å¼ºå¤§çš„é€»è¾‘æ¨ç†èƒ½åŠ›**ï¼š
   - o1 åœ¨ç‰©ç†ã€åŒ–å­¦ã€æ•°å­¦ç­‰å¼ºé€»è¾‘é¢†åŸŸè¡¨ç°å‡ºè‰²ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¾å›½æ•°å­¦å¥¥æ—åŒ¹å…‹é¢„é€‰èµ›ï¼ˆAIMEï¼‰ä¸­ï¼Œo1 çš„å‡†ç¡®ç‡è¾¾åˆ°äº†74%ï¼Œè¿œè¶…GPT-4çš„12%ã€‚åœ¨GPQA Diamondæµ‹è¯•ä¸­ï¼Œo1 è¶…è¿‡äº†PhDçº§åˆ«çš„äººç±»ä¸“å®¶ã€‚

4. **æ‹ŸäººåŒ–çš„æ¨ç†æ¨¡å¼**ï¼š
   - o1 åœ¨å›ç­”é—®é¢˜æ—¶ä¼šè¿›å…¥æ‹ŸäººåŒ–æ€è€ƒæ¨¡å¼ï¼Œè¿™ç§æ¨¡å¼ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£é—®é¢˜çš„æœ¬è´¨ï¼Œåˆ†æé—®é¢˜çš„å„ä¸ªæ–¹é¢ï¼Œä»è€Œç»™å‡ºæ›´å‡†ç¡®å’Œåˆç†çš„ç­”æ¡ˆã€‚

5. **è‡ªé€‚åº”å¼ºåŒ–å­¦ä¹ å’Œçº é”™**ï¼š
   - o1 é€šè¿‡å¤§è§„æ¨¡çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿä¸æ–­ä¼˜åŒ–è‡ªå·±çš„ç­–ç•¥ï¼Œè¯†åˆ«å’Œçº æ­£é”™è¯¯ï¼Œå­¦ä¼šå°†å¤æ‚çš„æ­¥éª¤åˆ†è§£ä¸ºæ›´ç®€å•çš„éƒ¨åˆ†ï¼Œå¹¶åœ¨å½“å‰æ–¹æ³•ä¸å¥æ•ˆæ—¶å°è¯•ä¸åŒçš„æ–¹æ³•æ¥è§£å†³ã€‚

#### å€¼å¾—å…³æ³¨çš„ç‚¹

1. **è®­ç»ƒå’Œæ¨ç†ç®—åŠ›çš„å¢åŠ **ï¼š
   - ç”±äºå¼•å…¥äº†å¼ºåŒ–å­¦ä¹ å’Œæ›´é•¿çš„å†…éƒ¨æ€ç»´é“¾ï¼Œo1 åœ¨åè®­ç»ƒå’Œæ¨ç†é˜¶æ®µéœ€è¦æ›´å¤šçš„ç®—åŠ›ã€‚è¿™å¯èƒ½å¯¹ç¡¬ä»¶å’Œè®¡ç®—èµ„æºæå‡ºæ›´é«˜çš„è¦æ±‚ã€‚

2. **å¤šé¢†åŸŸæ³›åŒ–èƒ½åŠ›çš„æå‡**ï¼š
   - éšç€RLå’ŒCoTçš„ä¸æ–­è¿­ä»£ï¼Œo1 åŠåç»­æ¨¡å‹æœ‰æœ›å‡ºç°â€œæ¶Œç°â€ç°è±¡ï¼Œå°†èƒ½åŠ›æ³›åŒ–åˆ°å¼ºé€»è¾‘ä»¥å¤–çš„é€šç”¨é—®é¢˜é¢†åŸŸï¼Œè¿™å¯èƒ½å¯¹å¤æ‚AIåº”ç”¨çš„è¿­ä»£å’Œå‘å±•äº§ç”Ÿé‡è¦å½±å“ã€‚

3. **åº”ç”¨åœºæ™¯çš„æ‰©å±•**ï¼š
   - o1 çš„å¼ºå¤§æ¨ç†èƒ½åŠ›ä½¿å…¶åœ¨æ•™è‚²ã€ç§‘ç ”ã€ç¼–ç¨‹ç«èµ›ç­‰å¤šä¸ªé¢†åŸŸéƒ½æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œå®ƒå¯ä»¥ç”¨äºè¾…åŠ©æ•™å­¦ã€è§£å†³å¤æ‚çš„ç§‘ç ”é—®é¢˜ã€ç¼–å†™å¤æ‚çš„ä»£ç ç­‰ã€‚

4. **æŠ€æœ¯è¿›æ­¥çš„ä¸ç¡®å®šæ€§**ï¼š
   - å°½ç®¡o1 å±•ç¤ºäº†å¼ºå¤§çš„æ€§èƒ½ï¼Œä½†AIæŠ€æœ¯çš„è¿›æ­¥ä»ç„¶å­˜åœ¨ä¸ç¡®å®šæ€§ã€‚å®è§‚ç»æµæ³¢åŠ¨ã€æŠ€æœ¯å‘å±•ä¸åŠé¢„æœŸç­‰å› ç´ éƒ½å¯èƒ½å½±å“o1 åŠå…¶åç»­æ¨¡å‹çš„å‘å±•ã€‚

5. **å›½å†…ç®—åŠ›é“¾å’ŒAIåº”ç”¨çš„å‘å±•**ï¼š
   - o1 çš„å‘å¸ƒä¸ºå›½å†…ç®—åŠ›é“¾ã€è‹¹æœé“¾å’Œæ ¸å¿ƒAIåº”ç”¨ç›¸å…³å…¬å¸å¸¦æ¥äº†æ–°çš„æœºé‡å’ŒæŒ‘æˆ˜ã€‚å»ºè®®å…³æ³¨è¿™äº›é¢†åŸŸçš„åŠ¨æ€ï¼Œä»¥æŠ“ä½æ½œåœ¨çš„æŠ•èµ„æœºä¼šã€‚

### æ€»ç»“
OpenAI o1 æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ å’Œæ›´é•¿çš„å†…éƒ¨æ€ç»´é“¾ï¼Œæ˜¾è‘—æå‡äº†åœ¨ç‰©ç†ã€åŒ–å­¦ã€æ•°å­¦ç­‰å¼ºé€»è¾‘é¢†åŸŸçš„æ€§èƒ½ã€‚å…¶æ‹ŸäººåŒ–çš„æ¨ç†æ¨¡å¼å’Œè‡ªé€‚åº”å¼ºåŒ–å­¦ä¹ èƒ½åŠ›ä½¿å…¶åœ¨å¤šä¸ªåº”ç”¨åœºæ™¯ä¸­å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œè¿™ä¹Ÿå¸¦æ¥äº†å¯¹ç®—åŠ›å’Œè®¡ç®—èµ„æºçš„æ›´é«˜è¦æ±‚ï¼Œå€¼å¾—ç›¸å…³ä¼ä¸šå’Œç ”ç©¶æœºæ„å…³æ³¨ã€‚
```
## ğŸ† Benchmark

### ğŸš¶ğŸ¼â€â™‚ Running Tests

Script for evaluating open-source modelsï¼š[open_model_terminal.sh](example/run_benchmark/open_model_terminal.sh)

Set running parametersï¼š

- `MODEL_NAME_OR_PATH` Model path/name
- `ALL_GPUS` Total number of hardware units
- `NUM_SERVICES` Number of vllm backend services
- `GPUS_PER_SERVICE` Number of GPUs used per service

```bash
cd example/run_benchmark
bash open_model_terminal.sh
```

Results are stored atï¼š[data/metrics_rlts](data/metrics_rlts)

### ğŸ”ï¸ Evaluation

Choose the name of the large model to be used as the evaluator and configure it in the [configuration file](config/.env)(`EVALUATOR_NAME`)

Evaluation scriptï¼š[llm_eval_terminal.sh](example/eval/llm_eval_terminal.sh)

Evaluate all jsonl files under `data/metrics_rlts`

```bash
cd example/eval
bash llm_eval_terminal.sh
```

## âœ¨ï¸ Citation

If our project has inspired your research/work, please cite it in the following format:
```
@article{chen2024mindsearch,
  title={},
  author={},
  journal={},
  year={2024}
}
```
